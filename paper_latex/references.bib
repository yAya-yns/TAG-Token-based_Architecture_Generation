 @misc{wu_schuster_chen_le_norouzi_macherey_krikun_cao_gao_macherey_et_al._2016, title={Google's Neural Machine Translation System: Bridging the gap between human and machine translation}, url={https://arxiv.org/abs/1609.08144}, journal={arXiv.org}, author={Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V. and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and et al.}, year={2016}, month={Oct}} 
 @misc{ppuda, title={Parameter prediction for unseen deep architectures}, url={https://arxiv.org/abs/2110.13100}, journal={arXiv.org}, author={Knyazev, Boris and Drozdzal, Michal and Taylor, Graham W. and Romero-Soriano, Adriana}, year={2021}, month={Oct}} 
 @misc{ren_he_girshick_sun_2016, title={Faster R-CNN: Towards real-time object detection with region proposal networks}, url={https://arxiv.org/abs/1506.01497}, journal={arXiv.org}, author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian}, year={2016}, month={Jan}} 
 @misc{ren_xiao_chang_huang_li_chen_wang_2021, title={A comprehensive survey of neural architecture search: Challenges and solutions}, url={https://arxiv.org/abs/2006.02903}, journal={arXiv.org}, author={Ren, Pengzhen and Xiao, Yun and Chang, Xiaojun and Huang, Po-Yao and Li, Zhihui and Chen, Xiaojiang and Wang, Xin}, year={2021}, month={Mar}} 
 @misc{simonyan_zisserman_2015, title={Very deep convolutional networks for large-scale image recognition}, url={https://arxiv.org/abs/1409.1556}, journal={arXiv.org}, author={Simonyan, Karen and Zisserman, Andrew}, year={2015}, month={Apr}} 
 @misc{brown_mann_ryder_subbiah_kaplan_dhariwal_neelakantan_shyam_sastry_askell_et_al._2020, title={Language models are few-shot learners}, url={https://arxiv.org/abs/2005.14165}, journal={arXiv.org}, author={Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and et al.}, year={2020}, month={Jul}} 

 @misc{krenn_häse_nigam_friederich_aspuru-guzik_2020, title={Self-referencing embedded strings (selfies): A 100\% robust molecular string representation}, url={https://arxiv.org/abs/1905.13741}, journal={arXiv.org}, author={Krenn, Mario and Häse, Florian and Nigam, AkshatKumar and Friederich, Pascal and Aspuru-Guzik, Alán}, year={2020}, month={Mar}} 

 @misc{luo_tian_qin_chen_liu_2019, title={Neural architecture optimization}, url={https://arxiv.org/abs/1808.07233}, journal={arXiv.org}, author={Luo, Renqian and Tian, Fei and Qin, Tao and Chen, Enhong and Liu, Tie-Yan}, year={2019}, month={Sep}} 

 @misc{liu_simonyan_yang_2019, title={Darts: Differentiable architecture search}, url={https://arxiv.org/abs/1806.09055}, journal={arXiv.org}, author={Liu, Hanxiao and Simonyan, Karen and Yang, Yiming}, year={2019}, month={Apr}} 

 @misc{attentionIsAllYouNeed, title={Attention is all you need}, url={https://arxiv.org/abs/1706.03762}, journal={arXiv.org}, author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia}, year={2017}, month={Dec}} 

 @misc{kim_nguyen_min_cho_lee_lee_hong_2022, title={Pure transformers are powerful graph learners}, url={https://arxiv.org/abs/2207.02505}, journal={arXiv.org}, author={Kim, Jinwoo and Nguyen, Tien Dat and Min, Seonwoo and Cho, Sungjun and Lee, Moontae and Lee, Honglak and Hong, Seunghoon}, year={2022}, month={Oct}} 

 @misc{huang_vaswani_uszkoreit_shazeer_simon_hawthorne_dai_hoffman_dinculescu_eck_et_al._2018, title={Music transformer}, url={https://arxiv.org/abs/1809.04281}, journal={arXiv.org}, author={Huang, Cheng-Zhi Anna and Vaswani, Ashish and Uszkoreit, Jakob and Shazeer, Noam and Simon, Ian and Hawthorne, Curtis and Dai, Andrew M. and Hoffman, Matthew D. and Dinculescu, Monica and Eck, Douglas and et al.}, year={2018}, month={Dec}} 
 @misc{zhang_song_li_zhou_song_2022, title={A survey of controllable text generation using transformer-based pre-trained language models}, url={https://arxiv.org/abs/2201.05337}, journal={arXiv.org}, author={Zhang, Hanqing and Song, Haolin and Li, Shaoyu and Zhou, Ming and Song, Dawei}, year={2022}, month={Jan}} 
 @misc{wen_liu_li_chen_bender_kindermans_2019, title={Neural predictor for neural architecture search}, url={https://arxiv.org/abs/1912.00848}, journal={arXiv.org}, author={Wen, Wei and Liu, Hanxiao and Li, Hai and Chen, Yiran and Bender, Gabriel and Kindermans, Pieter-Jan}, year={2019}, month={Dec}} 

 @misc{hutter, title={AutoML: Towards Deep Learning 2.0}, url={https://www.dropbox.com/s/amqno70w097laka/Frank_Hutter_TMLS_Keynote_2021__Towards_DL2.0.pdf?dl=0}, journal={AutoML.org}, author={Hutter, Frank}}  

 @misc{DARTS,
  doi = {10.48550/ARXIV.1806.09055},
  url = {https://arxiv.org/abs/1806.09055},
  author = {Liu, Hanxiao and Simonyan, Karen and Yang, Yiming},
  keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {DARTS: Differentiable Architecture Search},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{NAO,
  doi = {10.48550/ARXIV.1808.07233},
  url = {https://arxiv.org/abs/1808.07233},
  author = {Luo, Renqian and Tian, Fei and Qin, Tao and Chen, Enhong and Liu, Tie-Yan},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Neural Architecture Optimization},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{ENAS,
  doi = {10.48550/ARXIV.1802.03268},
  url = {https://arxiv.org/abs/1802.03268},
  author = {Pham, Hieu and Guan, Melody Y. and Zoph, Barret and Le, Quoc V. and Dean, Jeff},
  keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL), Computer Vision and Pattern Recognition (cs.CV), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Efficient Neural Architecture Search via Parameter Sharing},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{SMASH,
  doi = {10.48550/ARXIV.1708.05344},
  url = {https://arxiv.org/abs/1708.05344},
  author = {Brock, Andrew and Lim, Theodore and Ritchie, J. M. and Weston, Nick},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {SMASH: One-Shot Model Architecture Search through HyperNetworks},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{AutoGAN,
  doi = {10.48550/ARXIV.1908.03835},
  url = {https://arxiv.org/abs/1908.03835},
  author = {Gong, Xinyu and Chang, Shiyu and Jiang, Yifan and Wang, Zhangyang},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Image and Video Processing (eess.IV), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  title = {AutoGAN: Neural Architecture Search for Generative Adversarial Networks},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{ContinualAndMultiTask,
  doi = {10.48550/ARXIV.1906.05226},
  url = {https://arxiv.org/abs/1906.05226},
  author = {Pasunuru, Ramakanth and Bansal, Mohit},
  keywords = {Computation and Language (cs.CL), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Continual and Multi-Task Architecture Search},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{evaluate_NAS,
  doi = {10.48550/ARXIV.1902.08142},
  url = {https://arxiv.org/abs/1902.08142},
  author = {Yu, Kaicheng and Sciuto, Christian and Jaggi, Martin and Musat, Claudiu and Salzmann, Mathieu},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Evaluating the Search Phase of Neural Architecture Search},
  publisher = {arXiv},
  year = {2019},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}

@misc{DAG_GNN,
  doi = {10.48550/ARXIV.2101.07965},
  url = {https://arxiv.org/abs/2101.07965},
  author = {Thost, Veronika and Chen, Jie},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Directed Acyclic Graph Neural Networks},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{GHN,
  doi = {10.48550/ARXIV.1810.05749},
  url = {https://arxiv.org/abs/1810.05749},
  author = {Zhang, Chris and Ren, Mengye and Urtasun, Raquel},
  keywords = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Graph HyperNetworks for Neural Architecture Search},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{GNN,
  doi = {10.48550/ARXIV.1812.08434},
  url = {https://arxiv.org/abs/1812.08434},
  author = {Zhou, Jie and Cui, Ganqu and Hu, Shengding and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Graph Neural Networks: A Review of Methods and Applications},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{pure,
  doi = {10.48550/ARXIV.2207.02505},
  url = {https://arxiv.org/abs/2207.02505},
  author = {Kim, Jinwoo and Nguyen, Tien Dat and Min, Seonwoo and Cho, Sungjun and Lee, Moontae and Lee, Honglak and Hong, Seunghoon},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Pure Transformers are Powerful Graph Learners},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{2-IGN,
  doi = {10.48550/ARXIV.1812.09902},
  url = {https://arxiv.org/abs/1812.09902},
  author = {Maron, Haggai and Ben-Hamu, Heli and Shamir, Nadav and Lipman, Yaron},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Invariant and Equivariant Graph Networks},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{SELFIES,
	doi = {10.1088/2632-2153/aba947},
	url = {https://doi.org/10.1088%2F2632-2153%2Faba947},
	year = 2020,
	month = {oct},
	publisher = {{IOP} Publishing},
	volume = {1},
	number = {4},
	pages = {045024},
	author = {Mario Krenn and Florian Häse and AkshatKumar Nigam and Pascal Friederich and Alan Aspuru-Guzik},
	title = {Self-referencing embedded strings ({SELFIES}): A 100{\%} robust molecular string representation},
	journal = {Machine Learning: Science and Technology}
}

@misc{VAE,
  doi = {10.48550/ARXIV.1312.6114},
  url = {https://arxiv.org/abs/1312.6114},
  author = {Kingma, Diederik P and Welling, Max},
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Auto-Encoding Variational Bayes},
  publisher = {arXiv},
  year = {2013},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{GAN,
  doi = {10.48550/ARXIV.1406.2661},
  url = {https://arxiv.org/abs/1406.2661},
  author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Generative Adversarial Networks},
  publisher = {arXiv},
  year = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{GANformer,
  doi = {10.48550/ARXIV.2103.01209},
  url = {https://arxiv.org/abs/2103.01209},
  author = {Hudson, Drew A. and Zitnick, C. Lawrence},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Generative Adversarial Transformers},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{TransGAN,
  doi = {10.48550/ARXIV.2102.07074},
  url = {https://arxiv.org/abs/2102.07074},
  author = {Jiang, Yifan and Chang, Shiyu and Wang, Zhangyang},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {TransGAN: Two Pure Transformers Can Make One Strong GAN, and That Can Scale Up},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{STransGAN,
author = {Xu, Rui and Xu, Xiangyu and Chen, Kai and Zhou, Bolei and Loy, Chen Change},
title = {STransGAN: An Empirical Study on Transformer in GANs},
booktitle = {arxiv},
month = {October},
year = {2021}
}

@misc{StyleSwin,
  doi = {10.48550/ARXIV.2112.10762},
  url = {https://arxiv.org/abs/2112.10762},
  author = {Zhang, Bowen and Gu, Shuyang and Zhang, Bo and Bao, Jianmin and Chen, Dong and Wen, Fang and Wang, Yong and Guo, Baining},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {StyleSwin: Transformer-based GAN for High-resolution Image Generation},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{Gransformer,
  doi = {10.48550/ARXIV.2203.13655},
  url = {https://arxiv.org/abs/2203.13655},
  author = {Khajenezhad, Ahmad and Osia, Seyed Ali and Karimian, Mahmood and Beigy, Hamid},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Gransformer: Transformer-based Graph Generation},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{TokenGAN,
  doi = {10.48550/ARXIV.2111.03481},
  url = {https://arxiv.org/abs/2111.03481},
  author = {Zeng, Yanhong and Yang, Huan and Chao, Hongyang and Wang, Jianbo and Fu, Jianlong},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Improving Visual Quality of Image Synthesis by A Token-based Generator with Transformers},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{HuggingFace,
  title = {{HuggingFace Course on Transformer} },
  howpublished = {\url{https://huggingface.co/course/chapter1/1}},
  note = {Accessed: 2023-01-30}
}

@misc{NeurPred,
  doi = {10.48550/ARXIV.1912.00848},
  url = {https://arxiv.org/abs/1912.00848},
  author = {Wen, Wei and Liu, Hanxiao and Li, Hai and Chen, Yiran and Bender, Gabriel and Kindermans, Pieter-Jan},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Neural Predictor for Neural Architecture Search},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{NetworkX,
title = {Exploring network structure, dynamics, and function using networkx},
author = {Hagberg, Aric and Swart, Pieter and S Chult, Daniel},
abstractNote = {NetworkX is a Python language package for exploration and analysis of networks and network algorithms. The core package provides data structures for representing many types of networks, or graphs, including simple graphs, directed graphs, and graphs with parallel edges and self loops. The nodes in NetworkX graphs can be any (hashable) Python object and edges can contain arbitrary data; this flexibility mades NetworkX ideal for representing networks found in many different scientific fields. In addition to the basic data structures many graph algorithms are implemented for calculating network properties and structure measures: shortest paths, betweenness centrality, clustering, and degree distribution and many more. NetworkX can read and write various graph formats for eash exchange with existing data, and provides generators for many classic graphs and popular graph models, such as the Erdoes-Renyi, Small World, and Barabasi-Albert models, are included. The ease-of-use and flexibility of the Python programming language together with connection to the SciPy tools make NetworkX a powerful tool for scientific computations. We discuss some of our recent work studying synchronization of coupled oscillators to demonstrate how NetworkX enables research in the field of computational networks.},
doi = {},
url = {https://www.osti.gov/biblio/960616}, journal = {},
place = {United States},
year = {2008},
month = {1}
}

@misc{NAS-Bench-Graph,
  doi = {10.48550/ARXIV.2206.09166},
  url = {https://arxiv.org/abs/2206.09166},
  author = {Qin, Yijian and Zhang, Ziwei and Wang, Xin and Zhang, Zeyang and Zhu, Wenwu},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {NAS-Bench-Graph: Benchmarking Graph Neural Architecture Search},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}

@misc{performance_predictor,
  doi = {10.48550/ARXIV.2104.01177},
  url = {https://arxiv.org/abs/2104.01177},
  author = {White, Colin and Zela, Arber and Ru, Binxin and Liu, Yang and Hutter, Frank},
  keywords = {Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {How Powerful are Performance Predictors in Neural Architecture Search?},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@TECHREPORT{cifar10,
    author = "Alex Krizhevsky",
    title = "Learning Multiple Layers of Features from Tiny Images",
    institution = "University of Toronto",
    year = "2009"
}

@ARTICLE{kendal_tau,
    author={M. G. Kendall},
    journal={The Annals of Mathematical Statistics},
    title={A New Measure of Rank Correlation},
    year={1938},
    volume={9},
    number={3},
    pages={122--127},
    doi={10.1214/aoms/1177732360}
}